{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of, you need to **run the following command on terminal** to start running the api on the local server:\n",
    "\n",
    "`uvicorn main:api --reload`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the first URL : The wikipedia page about Brazil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_index = 'https://en.wikipedia.org/wiki/Brazil'\n",
    "query1 = \"What is the population of Brazil?\"\n",
    "query2 = \"when was the Treaty of Tordesillas?\"\n",
    "query3 = \"When did Pedro Álvares Cabral land in Brazil?\"\n",
    "query4 = \"Who was Pedro Alvares Cabral?\"\n",
    "query5 = \"How many states does Brazil have?\"\n",
    "query6 = \"What is the capital of Brazil?\"\n",
    "followup_query11 = \"and how big is its territory?\"\n",
    "followup_query12 = \"and when was the first settlement established?\"\n",
    "\n",
    "url_to_index2 = \"https://en.wikipedia.org/wiki/France\"\n",
    "query21 = \"What is capital of France?\"\n",
    "followup_query21 = \"and how many people live there?\"\n",
    "followup_query22 = \"and who is the its current president?\"\n",
    "followup_query23 = \"What have I just asked?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "BASE_URL = \"http://127.0.0.1:8000\"  # Make sure FastAPI is running\n",
    "user_id = \"defaultuser\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'URL indexed successfully'}\n"
     ]
    }
   ],
   "source": [
    "# Test Indexing\n",
    "index_response = requests.post(f\"{BASE_URL}/index_url/\", params={\"url\": url_to_index})\n",
    "\n",
    "print(index_response.json())  # Should return \"URL indexed successfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'The population of Brazil was approximately 210.86 million on July 1, 2022.'}\n"
     ]
    }
   ],
   "source": [
    "# Test Asking\n",
    "ask_response = requests.get(f\"{BASE_URL}/ask/\", params={\"url\": url_to_index, \"question\": query1})\n",
    "\n",
    "print(ask_response.json())  # Should return the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the latest official projection, it is estimated that Brazil’s population was 210,862,983 on July 1, 2022—an adjustment of 3.9% from the initial figure of 203 million reported by the 2022 census.[354] The population of Brazil, as recorded by the 2008 PNAD, was approximately 190 million[355] (22.31 inhabitants per square kilometer or 57.8/sq mi), with a ratio of men to women of 0.95:1[356] and 83.75% of the population defined as urban.[357] The population is heavily concentrated in the Southeastern (79.8 million inhabitants) and Northeastern (53.5 million inhabitants) regions, while the two most extensive regions, the Center-West and the North, which together make up 64.12% of the Brazilian territory, have a total of only 29.1 million inhabitants.\n",
      "\n",
      "[0.7869417]\n",
      "[8.908005]\n"
     ]
    }
   ],
   "source": [
    "# Test retrieval \n",
    "retrieval_response = requests.get(f\"{BASE_URL}/get_retrieval_text_and_similarity/\", params={\"url\": url_to_index, \"question\": query1})\n",
    "\n",
    "print(retrieval_response.json()['context']) # Should return the best mathcing paragraph and its cossine similarity\n",
    "print(retrieval_response.json()['cossine_similarity'])\n",
    "print(retrieval_response.json()['rerank_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'The population of Brazil was approximately 211 million in 2022.'}\n"
     ]
    }
   ],
   "source": [
    "# Test chat\n",
    "chat_response = requests.get(f\"{BASE_URL}/chat/\", params={\"url\": url_to_index, \"question\": query1,\n",
    "                                                           \"user_id\": user_id})\n",
    "\n",
    "print(chat_response.json())  # Should return the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'The territory of Brazil covers approximately 8.5 million square kilometers.'}\n"
     ]
    }
   ],
   "source": [
    "# Test followup questions\n",
    "followup11_response = requests.get(f\"{BASE_URL}/chat/\", params={\"url\": url_to_index, \"question\": followup_query11,\n",
    "                                                           \"user_id\": user_id})\n",
    "print(followup11_response.json())  # Should return the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'The first settlement in Brazil was established in 1532.'}\n"
     ]
    }
   ],
   "source": [
    "# Test followup questions\n",
    "followup12_response = requests.get(f\"{BASE_URL}/chat/\", params={\"url\": url_to_index, \"question\": followup_query12,\n",
    "                                                           \"user_id\": user_id})\n",
    "print(followup12_response.json())  # Should return the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:What is the population of Brazil?\n",
      "Chatbot:The population of Brazil was approximately 211 million in 2022.\n",
      "User:and how big is its territory?\n",
      "Chatbot:The territory of Brazil covers approximately 8.5 million square kilometers.\n",
      "User:and when was the first settlement established?\n",
      "Chatbot:The first settlement in Brazil was established in 1532.\n"
     ]
    }
   ],
   "source": [
    "# Test get chat history\n",
    "chat_history_response = requests.get(f\"{BASE_URL}/get_chat_history/\", params={\"user_id\": user_id, \"url\": url_to_index})\n",
    "\n",
    "print(chat_history_response.json()['chat_history'])  # Should return the chat history # we just keep the last 10 messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the api on another URL with other questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'URL indexed successfully'}\n"
     ]
    }
   ],
   "source": [
    "# Test Indexing\n",
    "index_response = requests.post(f\"{BASE_URL}/index_url/\", params={\"url\": url_to_index2})\n",
    "\n",
    "print(index_response.json())  # Should return \"URL indexed successfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'Paris is the capital of France.'}\n"
     ]
    }
   ],
   "source": [
    "# Test Asking\n",
    "ask_response = requests.get(f\"{BASE_URL}/ask/\", params={\"url\": url_to_index2, \"question\": query21})\n",
    "\n",
    "print(ask_response.json())  # Should return the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France,[IX] officially the French Republic,[X] is a country located primarily in Western Europe. Its overseas regions and territories include French Guiana in South America, Saint Pierre and Miquelon in the North Atlantic, the French West Indies, and many islands in Oceania and the Indian Ocean, giving it one of the largest discontiguous exclusive economic zones in the world. Metropolitan France shares borders with Belgium and Luxembourg to the north, Germany to the northeast, Switzerland to the east, Italy and Monaco to the southeast, Andorra and Spain to the south, and a maritime border with the United Kingdom to the northwest. Its metropolitan area extends from the Rhine to the Atlantic Ocean and from the Mediterranean Sea to the English Channel and the North Sea. Its eighteen integral regions—five of which are overseas—span a combined area of 632,702 km2 (244,288 sq mi) and have an estimated total population of over 68.6 million as of January 2025[update]. France is a semi-presidential republic and its capital, largest city and main cultural and economic centre is Paris.\n",
      "\n",
      "[0.6673641]\n"
     ]
    }
   ],
   "source": [
    "# Test retrieval \n",
    "retrieval_response = requests.get(f\"{BASE_URL}/get_retrieval_text_and_similarity/\", params={\"url\": url_to_index2, \"question\": query21})\n",
    "\n",
    "print(retrieval_response.json()['context']) # Should return the best mathcing paragraph and its cossine similarity\n",
    "print(retrieval_response.json()['cossine_similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'Paris is the capital of France.'}\n"
     ]
    }
   ],
   "source": [
    "# Test chat\n",
    "chat_response = requests.get(f\"{BASE_URL}/chat/\", params={\"url\": url_to_index2, \"question\": query21,\n",
    "                                                           \"user_id\": user_id})\n",
    "\n",
    "print(chat_response.json())  # Should return the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'The population of France is approximately 68.6 million people.'}\n"
     ]
    }
   ],
   "source": [
    "# Test followup questions\n",
    "followup21_response = requests.get(f\"{BASE_URL}/chat/\", params={\"url\": url_to_index2, \"question\": followup_query21,\n",
    "                                                           \"user_id\": user_id})\n",
    "print(followup21_response.json())  # Should return the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using an LLM and intentionally did not set a seed to avoid limiting the model’s responses, at times, the model interprets the question above as being related to Paris and, therefore, responds with “I don’t have enough information.” However, in other instances, it understands that the question is about France and finds the information in the context, responding as shown above. My conclusion is that the question is indeed ambiguous, and to me, both of the model’s reactions make sense!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'The current president of France is Emmanuel Macron.'}\n"
     ]
    }
   ],
   "source": [
    "# Test followup questions\n",
    "followup22_response = requests.get(f\"{BASE_URL}/chat/\", params={\"url\": url_to_index2, \"question\": followup_query22,\n",
    "                                                           \"user_id\": user_id})\n",
    "print(followup22_response.json())  # Should return the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': \"What have I just asked for?      I've asked for information about the current president of France.\"}\n"
     ]
    }
   ],
   "source": [
    "# Test followup questions\n",
    "followup23_response = requests.get(f\"{BASE_URL}/chat/\", params={\"url\": url_to_index2, \"question\": followup_query23,\n",
    "                                                           \"user_id\": user_id})\n",
    "print(followup23_response.json())  # Should return the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we see a limitation of an LLM (especially a smaller and quantized one!): even when explicitly instructing in the prompt not to repeat the question in the response, the model still does so, making the output cluttered, even if the answer is correct. For the same reason, it’s also worth mentioning that restricting the model’s knowledge to the given context doesn’t always work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:What is capital of France?\n",
      "Chatbot:Paris is the capital of France.\n",
      "User:and how many people live there?\n",
      "Chatbot:The population of France is approximately 68.6 million people.\n",
      "User:and who is the its current president?\n",
      "Chatbot:The current president of France is Emmanuel Macron.\n",
      "User:What have I just asked?\n",
      "Chatbot:What have I just asked for?      I've asked for information about the current president of France.\n"
     ]
    }
   ],
   "source": [
    "# Test get chat history\n",
    "chat_history_response = requests.get(f\"{BASE_URL}/get_chat_history/\", params={\"user_id\": user_id, \"url\": url_to_index2})\n",
    "\n",
    "print(chat_history_response.json()['chat_history'])  # Should return the chat history # we just keep the last 10 messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, I believe we can conclude that the results were quite satisfactory. Obviously, with more powerful hardware, the time overhead caused by using LLMs would be mitigated. There are several areas for improvement, including how to handle the model’s responses and the fact that it can still hallucinate and make mistakes, even with the temperature set to 0.0. However, I think all functionalities have been implemented in a simple, direct, and objective manner. Moreover, they work well, and the results are interesting!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "findlyvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
